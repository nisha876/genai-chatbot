# ğŸ“„ PDF-Aware GenAI Chatbot

A full-stack AI chatbot that reads any uploaded PDF and answers user questions based on its content using Cohereâ€™s LLM API.

ğŸ”— **Live Demo:**
- **Frontend:** https://genai-chatbot.vercel.app  
- **Backend:** https://genai-chatbot.onrender.com

---

## ğŸš€ Features

- ğŸ“¤ Upload any PDF document
- ğŸ’¬ Ask questions based on that document
- ğŸ§  Uses embeddings + retrieval to find relevant content
- ğŸ¤– Generates answers using Cohere's Command R+ model
- ğŸŒ Full-stack: React (frontend) + Flask (backend)
- âš™ï¸ Uses FAISS for vector similarity search

---

## ğŸ› ï¸ Tech Stack

| Layer      | Tech Used         |
|------------|-------------------|
| Frontend   | React, Vercel     |
| Backend    | Flask, Render     |
| LLM API    | [Cohere Command R+](https://cohere.com) |
| Embeddings | Cohere Embeddings |
| Vector DB  | FAISS             |

---

## ğŸ“‚ Project Structure

genai-chatbot/
â”œâ”€â”€ frontend/ # React app (deployed to Vercel)
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ App.js
â”‚ â”‚ â”œâ”€â”€ ChatBox.js
â”‚ â”‚ â”œâ”€â”€ api.js # Connects to backend API
â”œâ”€â”€ backend/ # Flask server (deployed to Render)
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ utils/
â”‚ â”‚ â”œâ”€â”€ pdf_utils.py
â”‚ â”‚ â””â”€â”€ vector_store.py
â”‚ â”œâ”€â”€ .env # (Not pushed to GitHub)
â”‚ â””â”€â”€ requirements.txt

## ğŸ§ª How It Works

1. PDF is uploaded and split into text chunks
2. Text chunks are embedded via Cohere's API
3. Stored in FAISS index
4. When a question is asked:
   - Embedding for query is computed
   - Top relevant chunks retrieved
   - Sent to Cohere's LLM for answering

---

## ğŸ” Environment Variables

Only needed in `backend/.env`:
COHERE_API_KEY=your-real-cohere-api-key-here


Never commit your `.env` file â€” instead, set it in Renderâ€™s **Environment** tab.

---

## âš™ï¸ Deployment Setup

### âœ… Backend (Render)
- Create new Web Service from GitHub
- Root directory: `backend/`
- Start command: `python app.py`
- Add env var: `COHERE_API_KEY`
- Make sure `app.py` uses:
  ```python
  app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)))
âœ… Frontend (Vercel)
Import from GitHub

Root directory: frontend/

Hardcode backend URL in src/api.js:
const BACKEND_URL = "(https://genai-chatbot-hql9.onrender.com)";

Deployment link:  https://genai-chatbot-delta.vercel.app/
ğŸ“Œ To Run Locally
# Backend
cd backend
pip install -r requirements.txt
touch .env            # Add your Cohere API key
python app.py

# Frontend
cd frontend
npm install
npm start             # Visit http://localhost:3000
